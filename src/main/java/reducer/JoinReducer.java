package reducer;

import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

// 这个reducer里边的注释基本上需要全部重来
// 有问题可以问gpt老师
// 但是请不要全部相信gpt的话，他很多时候在胡说
// 贴上去之前，好好看一眼，他在说些啥，我实现的是啥
// 可以参考我之前写的两个mapper，参考，不是ctrl+c ctrl+v
// 同理另一个reducer也是这样，需要重开
// 都我来很累的啦
// 稍微用点心，谢谢你

/**
 * Reducer class is typically responsible for aggregating, summarizing, or otherwise processing the intermediate data generated by the Mapper.
 * This class handle the aggregation and organization of different types of orders based on the information provided by the Mapper.
 * Input: <LongWritable, Text> - Input key-value pair.
 * Output: <NullWritable, Text> - Output key-value pair with NULL key and filtered trade records as the value.
 */
public class JoinReducer extends Reducer<LongWritable, Text, NullWritable, Text> {

    /**
     * Reduce input key-value pairs to intermediate key-value pairs.
     *
     * @param key     The input key.
     * @param values  The input value.
     * @param context The context object for emitting output.
     *                The output key is time, output value is composed by those useful fields in the original record in the format of final output.
     */
    @Override
    protected void reduce(LongWritable key, Iterable<Text> values, Context context)
            throws IOException, InterruptedException {
        List<DataRecord> records = new ArrayList<>();

        // Iterate through values and store in a list
        for (Text value : values) {
            String[] fields = value.toString().split(",");
            String sequenceNumber = fields[5];
            records.add(new DataRecord(sequenceNumber, value.toString()));
        }

        // Custom sorting based on time and sequence number
        Collections.sort(records);

        // Output the sorted records
        for (DataRecord record : records) {
            context.write(NullWritable.get(), new Text(record.getData()));
        }
    }

    /**
     * 这里原来的描述不对，重来
     */
    private static class DataRecord implements Comparable<DataRecord> {
        private final String sequenceNumber;
        private final String data;

        public DataRecord(String sequenceNumber, String data) {
            this.sequenceNumber = sequenceNumber;
            this.data = data;
        }

        public String getData() {
            return data;
        }

        /**
         * The compareTo method compares based on the sequenceNumber field in ascending order.
         */
        @Override
        public int compareTo(DataRecord other) {
            return Integer.compare(Integer.parseInt(this.sequenceNumber), Integer.parseInt(other.sequenceNumber));
        }
    }
}
